{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dir = \"../datasets/oor/inference/experiment_2907/\"\n",
    "# total_images = 23322\n",
    "\n",
    "exp_dir = \"../datasets/oor/inference/experiment_1208/\"\n",
    "exclude_set = set([f\"0-D12M08Y2024-H10M10S02-{i}\" for i in range(7425, 7615)])\n",
    "# exclude_set = set()\n",
    "total_images = 14986 - len(exclude_set)\n",
    "\n",
    "exp_names = sorted(next(os.walk(exp_dir))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tps = set.union(\n",
    "    *(set([f.stem \n",
    "           for f in pathlib.Path(os.path.join(exp_dir, name, \"actual_containers\")).glob(\"*.jpg\")\n",
    "          ]) for name in exp_names)) - exclude_set\n",
    "\n",
    "print(f\"Total number of TPs: {len(all_tps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "for name in exp_names:\n",
    "    detections = set([f.stem for f in pathlib.Path(os.path.join(exp_dir, name, \"detected_images\")).glob(\"*.jpg\") if f.stem not in exclude_set])\n",
    "    tps = set([f.stem for f in pathlib.Path(os.path.join(exp_dir, name, \"actual_containers\")).glob(\"*.jpg\") if f.stem not in exclude_set])\n",
    "    # tps = set.intersection(detections, all_tps)\n",
    "    experiments.append(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"detections\": detections,\n",
    "            \"n_detections\": len(detections),\n",
    "            \"true_positives\": tps,\n",
    "            \"n_true_positives\": len(tps),\n",
    "            \"precision\": len(tps) / len(detections),\n",
    "            \"partial_recall\": len(tps) / len(all_tps),\n",
    "            \"fnr\": len(detections - tps) / total_images,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.DataFrame(data=experiments)[['name', 'n_detections', 'n_true_positives', 'precision', 'partial_recall', 'fnr']]\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frame metadata\n",
    "\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "\n",
    "# metadata_folder = \"../datasets/oor/experiment_240812/\"\n",
    "metadata_folder = \"../datasets/oor/metadata_240826/3/\"\n",
    "\n",
    "RD_CRS = \"EPSG:28992\"  # CRS code for the Dutch Rijksdriehoek coordinate system\n",
    "LAT_LON_CRS = \"EPSG:4326\"  # CRS code for WGS84 latitude/longitude coordinate system\n",
    "\n",
    "def load_metadata_csv(metadata_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(metadata_file)\n",
    "    frame_base_name = f\"0-{pathlib.Path(metadata_file).stem.split(sep='-', maxsplit=1)[1]}\"\n",
    "    df[\"frame_name\"] = [f\"{frame_base_name}-{frame_id}\" for frame_id in df[\"pylon://0_frame_counter\"]]\n",
    "    return df.set_index(\"frame_name\")\n",
    "\n",
    "metadata_files = pathlib.Path(metadata_folder).glob(\"*.csv\")\n",
    "metadata_df = pd.concat(\n",
    "    [load_metadata_csv(metadata_file) for metadata_file in metadata_files]\n",
    ")\n",
    "\n",
    "metadata_gdf = gpd.GeoDataFrame(\n",
    "    metadata_df,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        x=metadata_df.gps_lon,\n",
    "        y=metadata_df.gps_lat,\n",
    "        crs=LAT_LON_CRS,\n",
    "    ),\n",
    ").sort_values(by=\"pylon://0_frame_counter\").to_crs(RD_CRS)\n",
    "\n",
    "del metadata_df, metadata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry as sg\n",
    "\n",
    "valid_points = metadata_gdf[metadata_gdf.distance(sg.Point(121000, 488000)) < 250000].geometry\n",
    "print(f\"Total distance: {sg.LineString(valid_points).length / 1000:.3f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_gdf = metadata_gdf[[True if name in all_tps else False for name in metadata_gdf.index]]\n",
    "tp_gdf = tp_gdf[[\"pylon://0_frame_counter\", \"geometry\"]]\n",
    "tp_gdf.columns = [\"frame_counter\", \"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    version = e[\"name\"].split(sep=\"_\", maxsplit=1)[0]\n",
    "    tps = [True if name in e[\"true_positives\"] else False for name in tp_gdf.index]\n",
    "    tp_gdf[e[\"name\"]] = tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _color_red_or_green(val):\n",
    "    color = 'green' if val else 'red'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "tp_gdf[['v1.0', 'v1.1', 'v2.0.0', 'v2.0.1', 'v2.1a', 'v2.1b', 'v2.1c0.01']].style.applymap(_color_red_or_green).to_excel('1208_comparison.xlsx', engine = 'openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_gdf.geometry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(metadata_gdf.index.str.startswith(\"8-D26M08Y2024-H10M55S09\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_conf_for_frame(frame: str, labels_dir: Union[str, os.PathLike], target_class: int = 2) -> float:\n",
    "    label_file = os.path.join(labels_dir, f\"{frame}.txt\")\n",
    "    with open(label_file, \"r\") as f:\n",
    "        max_conf = 0.\n",
    "        for line in f.readlines():\n",
    "            obj_class, _, _, _, _, conf = line.split(sep=\" \")[0:6]\n",
    "            obj_class = int(obj_class)\n",
    "            conf = float(conf)\n",
    "            if (obj_class == target_class) and (conf > max_conf):\n",
    "                max_conf = conf\n",
    "    return max_conf\n",
    "\n",
    "def fb_score(precision, recall, beta=1.):\n",
    "    return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"v2.1c0.01_solar_spaceship_10_conf_0.01\"\n",
    "\n",
    "tps = set([f.stem for f in pathlib.Path(os.path.join(exp_dir, name, \"actual_containers\")).glob(\"*.jpg\") if f.stem not in exclude_set])\n",
    "detections = {f.stem: get_conf_for_frame(f.stem, os.path.join(exp_dir, name, \"detected_labels\")) \n",
    "              for f in pathlib.Path(os.path.join(exp_dir, name, \"detected_images\")).glob(\"*.jpg\")\n",
    "              if f.stem not in exclude_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = np.arange(0., 1., 0.1)\n",
    "\n",
    "data = {\n",
    "    \"conf\": [],\n",
    "    \"n_det\": [],\n",
    "    \"n_tp\": [],\n",
    "    \"precision\": [],\n",
    "    \"partial_recall\": [],\n",
    "    \"fnr\": [],\n",
    "}\n",
    "\n",
    "for conf in confs:\n",
    "    conf_detections = set([frame for frame, confidence in detections.items() if confidence >= conf])\n",
    "    conf_tps = set.intersection(conf_detections, tps)\n",
    "    data[\"conf\"].append(conf)\n",
    "    data[\"n_det\"].append(len(conf_detections))\n",
    "    data[\"n_tp\"].append(len(conf_tps))\n",
    "    data[\"precision\"].append(len(conf_tps) / len(conf_detections))\n",
    "    data[\"partial_recall\"].append(len(conf_tps) / len(all_tps))\n",
    "    data[\"fnr\"].append(len(conf_detections - conf_tps) / total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df = pd.DataFrame(data=data).set_index(\"conf\")\n",
    "conf_df[\"f1\"] = fb_score(conf_df[\"precision\"], conf_df[\"partial_recall\"])\n",
    "conf_df[\"f0.5\"] = fb_score(conf_df[\"precision\"], conf_df[\"partial_recall\"], beta=0.5)\n",
    "conf_df[\"f2\"] = fb_score(conf_df[\"precision\"], conf_df[\"partial_recall\"], beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = conf_df[[\"precision\", \"partial_recall\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig(\"exp1208_v2.1_pr_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = conf_df[[\"f1\", \"f0.5\", \"f2\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig(\"exp1208_v2.1_f1_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "input_base_dir = pathlib.Path(exp_dir)\n",
    "output_dir = pathlib.Path(\"../datasets/oor/240812_all_tps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tps\n",
    "#   minus: tps of both v2.1 models\n",
    "# fps of v2.1 standard model\n",
    "\n",
    "# v21_tps = set.intersection(*(e[\"true_positives\"] for e in experiments if e[\"name\"].split(sep=\"_\", maxsplit=1)[0] in ('v2.1a', 'v2.1b')))\n",
    "# reduced_all_tps = all_tps - v21_tps\n",
    "reduced_all_tps = all_tps\n",
    "\n",
    "v21_detections = set.union(*(e[\"detections\"] for e in experiments if e[\"name\"].split(sep=\"_\", maxsplit=1)[0] in ('v2.1a', 'v2.1b')))\n",
    "v21_fps = v21_detections - all_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tp_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sorted = list(reversed([\"v2.1c0.01_solar_spaceship_10_conf_0.01\", \"v1.0_norect_500_100\", \"v1.1_600_best\", \"v2.0.0_rosy_grass_5\", \"v2.0.1_expert_jazz_9\", \"v2.1a_solar_spaceship_10\", \"v2.1b_vital-armadillo-11\"]))\n",
    "\n",
    "all_tps_map = {}\n",
    "\n",
    "for frame in reduced_all_tps:\n",
    "    for model in models_sorted:\n",
    "        if tp_gdf.loc[frame, model]:\n",
    "            all_tps_map[frame] = input_base_dir / model\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tps_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v21_detections = {\n",
    "    experiments[-3][\"name\"]: experiments[-3][\"detections\"],\n",
    "    experiments[-2][\"name\"]: experiments[-2][\"detections\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sorted = [\"v2.1a_solar_spaceship_10\", \"v2.1b_vital-armadillo-11\"]\n",
    "\n",
    "v21_fps_map = {}\n",
    "\n",
    "for frame in v21_fps:\n",
    "    for model in models_sorted:\n",
    "        if frame in v21_detections[model]:\n",
    "            v21_fps_map[frame] = input_base_dir / model\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_map = {**all_tps_map, **v21_fps_map}\n",
    "new_data_map = all_tps_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir / \"detections\", exist_ok=True)\n",
    "os.makedirs(output_dir / \"labels\", exist_ok=True)\n",
    "\n",
    "for frame, src_path in new_data_map.items():\n",
    "    shutil.copy2(src_path / \"detected_images\" / f\"{frame}.jpg\",\n",
    "                 output_dir / \"detections/\")\n",
    "    shutil.copy2(src_path / \"detected_labels\" / f\"{frame}.txt\",\n",
    "                 output_dir / \"labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
