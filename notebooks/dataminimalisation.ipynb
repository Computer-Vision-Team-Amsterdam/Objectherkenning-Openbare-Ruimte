{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell tells python to use the local version of CVToolkit instead of the installed one.\n",
    "# Use for testing purposes until branch feature/BCV-970-oor-metrics is merged.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../CVToolkit\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.metrics import tba_calculator\n",
    "from objectherkenning_openbare_ruimte.data_minimalisation_pipeline.source import blurring_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Scenario(Enum):\n",
    "    A = True, False, False, True\n",
    "    B = True, True, False, False\n",
    "    C = True, False, True, False, True\n",
    "\n",
    "    def __init__(self, blur_inside: bool, blur_outside: bool, crop: bool, draw_box: bool, fill_bg: bool = False):\n",
    "        self.blur_inside = blur_inside\n",
    "        self.blur_outside = blur_outside\n",
    "        self.crop = crop\n",
    "        self.draw_box = draw_box\n",
    "        self.fill_bg = fill_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../datasets/oor/data-minimalisation\"\n",
    "label_folder = \"predictions\"\n",
    "output_folder = \"../../datasets/oor/data-minimalisation/blurred\"\n",
    "\n",
    "blur_kernel_size_outside = 55\n",
    "blur_kernel_size_inside = 165\n",
    "blur_outside_padding = 25\n",
    "crop_padding = 25\n",
    "\n",
    "scenario = Scenario.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for img_file in pathlib.Path(os.path.join(data_folder, \"images\")).glob(\"*.png\"):\n",
    "    filename = img_file.stem\n",
    "    print(f\"=== {filename} ===\")\n",
    "    label_file = os.path.join(data_folder, label_folder, filename + \".txt\")\n",
    "\n",
    "    image_raw = cv2.imread(img_file.as_posix(), cv2.IMREAD_COLOR)\n",
    "\n",
    "    if not os.path.isfile(label_file):\n",
    "        print(\"Nothing to blur!\")\n",
    "    else:\n",
    "        with open(label_file, \"r\") as file:\n",
    "            lines = sorted(file.readlines())\n",
    "            for scenario in Scenario:\n",
    "                print(f\"--- Scenario {scenario.name} ---\")\n",
    "                image = image_raw.copy()\n",
    "                for line in lines:\n",
    "                    yolo_annotation = line.strip()\n",
    "                    class_id = int(yolo_annotation.split(sep=\" \", maxsplit=1)[0])\n",
    "                    if scenario.blur_inside and (class_id in (0, 1)):\n",
    "                        image = blurring_tools.blur_inside_yolo_box(\n",
    "                            image, yolo_annotation, blur_kernel_size_inside)\n",
    "                    if scenario.blur_outside and (class_id in (2,)):\n",
    "                        image = blurring_tools.blur_outside_yolo_box(\n",
    "                            image, yolo_annotation, blur_kernel_size_outside, blur_outside_padding)\n",
    "                    if scenario.crop and (class_id in (2,)):\n",
    "                        image = blurring_tools.crop_outside_yolo_box(image, yolo_annotation, crop_padding, scenario.fill_bg)\n",
    "                    if scenario.draw_box and (class_id in (2,)):\n",
    "                        image = blurring_tools.draw_yolo_box(image, yolo_annotation)\n",
    "                \n",
    "                out_path = os.path.join(output_folder, f\"{filename}_scen_{scenario.name}.jpg\")\n",
    "                cv2.imwrite(out_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "display(Image.fromarray(image[:, :, ::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(f\"../../datasets/oor/data-minimalisation/scenario_{scenario.name}.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all images with containers\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def get_labels(label_file: str) -> List[int]:\n",
    "    labels: List[int] = [0]*5\n",
    "    if not os.path.isfile(label_file):\n",
    "        return labels\n",
    "    with open(label_file, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            label = int(line.split(sep=\" \")[0])\n",
    "            labels[label] += 1\n",
    "    return labels\n",
    "\n",
    "data_folder = \"../../datasets/oor/first-train-oor-nc5\"\n",
    "\n",
    "data = {\n",
    "    \"filename\": [],\n",
    "    \"n_person\": [],\n",
    "    \"n_license_plate\": [],\n",
    "    \"n_container\": [],\n",
    "}\n",
    "\n",
    "images = list(pathlib.Path(os.path.join(data_folder, \"images\", \"val\")).glob(\"*.png\"))\n",
    "\n",
    "for img in images:\n",
    "    filename = img.stem\n",
    "    label_file = os.path.join(data_folder, \"labels\", \"val\", filename + \".txt\")\n",
    "    labels = get_labels(label_file)\n",
    "    data[\"filename\"].append(filename)\n",
    "    data[\"n_person\"].append(labels[0])\n",
    "    data[\"n_license_plate\"].append(labels[1])\n",
    "    data[\"n_container\"].append(labels[2])\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "filenames = df.query(\"n_container > 0 & (n_license_plate > 0 | n_person > 0)\")[\"filename\"].to_list()\n",
    "\n",
    "target_dir = \"../../datasets/oor/data-minimalisation\"\n",
    "\n",
    "pathlib.Path(os.path.join(target_dir, \"images\")).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(os.path.join(target_dir, \"labels\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in filenames:\n",
    "    img_src = os.path.join(data_folder, \"images\", \"val\", file + \".png\")\n",
    "    img_dst = os.path.join(target_dir, \"images\", file + \".png\")\n",
    "    shutil.copyfile(img_src, img_dst)\n",
    "    lab_src = os.path.join(data_folder, \"labels\", \"val\", file + \".txt\")\n",
    "    lab_dst = os.path.join(target_dir, \"labels\", file + \".txt\")\n",
    "    shutil.copyfile(lab_src, lab_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectherkenning-openbare-ruimte-xlfO-OLY-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
