{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell tells python to use the local version of CVToolkit instead of the installed one.\n",
    "# Use for testing purposes until branch feature/BCV-970-oor-metrics is merged.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../CVToolkit\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.metrics.per_pixel_stats import (\n",
    "    EvaluatePixelWise,\n",
    ")\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.metrics.metrics_utils import (\n",
    "    ObjectClass,\n",
    "    BoxSize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: ground truth and predictions\n",
    "gt_path = \"../../datasets/oor/eval_metrics_test/labels/ground_truth\"\n",
    "pred_path = \"../../datasets/oor/eval_metrics_test/labels/predictions\"\n",
    "\n",
    "# Size of the images (width, height)\n",
    "img_shape = (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance over classes and bounding box sizes\n",
    "\n",
    "evaluator = EvaluatePixelWise(gt_path, pred_path, img_shape)\n",
    "\n",
    "\n",
    "# Compute the Total Blurred Area results for the person & licence plate classes\n",
    "\n",
    "tba_results = evaluator.collect_results_per_class_and_size(\n",
    "    classes=[ObjectClass.person, ObjectClass.license_plate],\n",
    "    box_sizes=BoxSize\n",
    ")\n",
    "evaluator.store_tba_results(results=tba_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per pixel results \n",
    "\n",
    "per_pixel_results = evaluator.collect_results_per_class_and_size(\n",
    "    classes=ObjectClass,\n",
    "    box_sizes=[BoxSize.all]\n",
    ")\n",
    "\n",
    "pd.DataFrame(data=per_pixel_results).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
