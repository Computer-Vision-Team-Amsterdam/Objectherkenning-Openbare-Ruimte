{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.source.oor_evaluation import (\n",
    "    OOREvaluation, tba_result_to_df, per_image_result_to_df, custom_coco_result_to_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the images (width, height)\n",
    "img_shape = (1280, 720)\n",
    "gt_base_dir = \"../datasets/oor/processed-merged-batches-first-official-training-dataset-oor\"\n",
    "pred_base_dir = \"../datasets/oor/inference/processed_merged_v2\"\n",
    "output_dir = \"\"\n",
    "\n",
    "models = [\"yolov8m_1280_oor_v2_best\", \"yolov8_1280_oor_v2_noble_sweep_15\", \"yolov8_1280_oor_v2_cerulean_sweep_25\"]\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = models[2]\n",
    "pred_model_dir = os.path.join(pred_base_dir, model_name)\n",
    "\n",
    "OOREval = OOREvaluation(\n",
    "    ground_truth_base_folder=gt_base_dir,\n",
    "    predictions_base_folder=pred_model_dir,\n",
    "    output_folder=output_dir,\n",
    "    predictions_image_shape=img_shape,\n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Blurred Area evaluation\n",
    "tba_results = OOREval.tba_evaluation()\n",
    "tba_df = tba_result_to_df(tba_results)\n",
    "tba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per Image evaluation\n",
    "per_image_results = OOREval.per_image_evaluation()\n",
    "per_image_df = per_image_result_to_df(per_image_results)\n",
    "per_image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom COCO evaluation\n",
    "coco_results = OOREval.coco_evaluation()\n",
    "coco_df = custom_coco_result_to_df(coco_results)\n",
    "coco_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "cols_to_show = [\n",
    "    \"Model\",\n",
    "    \"Split\",\n",
    "    \"Object Class\",\n",
    "    \"AP@50_all\",\n",
    "    \"AP@50_small\",\n",
    "    \"AP@50_medium\",\n",
    "    \"AP@50_large\",\n",
    "    \"AR@50_all\",\n",
    "    \"AR@50_small\",\n",
    "    \"AR@50_medium\",\n",
    "    \"AR@50_large\",\n",
    "]\n",
    "\n",
    "# demo_df = coco_df[(coco_df[\"model_size\"]==\"m\") & (coco_df[\"img_size\"].isin((1024, 1920)))]\n",
    "demo_df = coco_df\n",
    "demo_df = demo_df[cols_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df[demo_df[\"Object Class\"]==\"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df[demo_df[\"Object Class\"]==\"container\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df[demo_df[\"Object Class\"]==\"person\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed look into one specific model / run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = splits[1]\n",
    "model = models[2]\n",
    "\n",
    "gt_annotations_folder = f\"{gt_base_dir}/labels/{split}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frame metadata\n",
    "\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "from typing import List, Union\n",
    "\n",
    "from cvtoolkit.datasets.yolo_labels_dataset import YoloLabelsDataset\n",
    "\n",
    "metadata_folder = \"../../datasets/oor/metadata\"\n",
    "\n",
    "RD_CRS = \"EPSG:28992\"  # CRS code for the Dutch Rijksdriehoek coordinate system\n",
    "LAT_LON_CRS = \"EPSG:4326\"  # CRS code for WGS84 latitude/longitude coordinate system\n",
    "\n",
    "def metadata_to_video_name(metadata_name: str) -> str:\n",
    "    metadata_split = metadata_name.split(sep=\"-\", maxsplit=1)\n",
    "    return f\"{metadata_split[0]}-0-{metadata_split[1]}\"\n",
    "\n",
    "def load_metadata_csv(metadata_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(metadata_file)\n",
    "    video_name = metadata_to_video_name(pathlib.Path(metadata_file).stem)\n",
    "    df[\"frame_name\"] = [f\"{video_name}_{frame_id:04}\" for frame_id in df[\"new_frame_id\"]]\n",
    "    return df.set_index(\"frame_name\")\n",
    "\n",
    "def get_target_cls_file_names(yolo_annotations_folder: str, target_cls: Union[ObjectClass, None] = None) -> List[str]:\n",
    "    yolo_dataset = YoloLabelsDataset(\n",
    "        folder_path=yolo_annotations_folder,\n",
    "        image_area=img_shape[0]*img_shape[1],\n",
    "    )\n",
    "    if target_cls:\n",
    "        yolo_dataset.filter_by_class(target_cls.value)\n",
    "    target_labels = yolo_dataset._filtered_labels\n",
    "    return [k for k, v in target_labels.items() if len(v) > 0]\n",
    "\n",
    "metadata_files = pathlib.Path(metadata_folder).glob(\"*.csv\")\n",
    "metadata_df = pd.concat(\n",
    "    [load_metadata_csv(metadata_file) for metadata_file in metadata_files]\n",
    ")\n",
    "\n",
    "metadata_gdf = gpd.GeoDataFrame(\n",
    "    metadata_df,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        x=metadata_df.gps_lon,\n",
    "        y=metadata_df.gps_lat,\n",
    "        crs=LAT_LON_CRS,\n",
    "    ),\n",
    ").to_crs(RD_CRS)\n",
    "\n",
    "del metadata_df, metadata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all detections of containers\n",
    "\n",
    "# Ground truth\n",
    "gt_container_names = get_target_cls_file_names(gt_annotations_folder, ObjectClass.container)\n",
    "keep_index = [frame in gt_container_names for frame in metadata_gdf.index]\n",
    "gt_gdf = metadata_gdf[keep_index]\n",
    "gt_gdf = gt_gdf[[\"gps_state\", \"geometry\"]]\n",
    "\n",
    "# Predictions\n",
    "pred_folder = f\"{pred_base_dir}/{model}/labels/{split}\"\n",
    "\n",
    "pred_container_names = get_target_cls_file_names(pred_folder, ObjectClass.container)\n",
    "keep_index = [frame in pred_container_names for frame in metadata_gdf.index]\n",
    "pred_gdf = metadata_gdf[keep_index]\n",
    "pred_gdf = pred_gdf[[\"gps_state\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances between ground truth and detections\n",
    "gt_gdf[\"distance\"] = gt_gdf[\"geometry\"].distance(pred_gdf[\"geometry\"].unary_union)\n",
    "pred_gdf[\"distance\"] = pred_gdf[\"geometry\"].distance(gt_gdf[\"geometry\"].unary_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance statistics\n",
    "import numpy as np\n",
    "\n",
    "stats = {\n",
    "    \"distance\": np.arange(0, 26, 5),\n",
    "    \"fnr\": [],\n",
    "    \"fpr\": [],\n",
    "}\n",
    "\n",
    "gt_total = len(gt_gdf)\n",
    "pred_total = len(pred_gdf)\n",
    "\n",
    "for dst in stats[\"distance\"]:\n",
    "    fn = np.count_nonzero(gt_gdf[\"distance\"] > dst)\n",
    "    fp = np.count_nonzero(pred_gdf[\"distance\"] > dst)\n",
    "    stats[\"fnr\"].append(fn/gt_total)\n",
    "    stats[\"fpr\"].append(fp/pred_total)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results on a map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "joined_gdf = gt_gdf.join(pred_gdf, how=\"outer\", lsuffix=\"_gt\", rsuffix=\"_pred\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "joined_gdf.set_geometry(\"geometry_gt\").plot(ax=ax, markersize=20)\n",
    "joined_gdf.set_geometry(\"geometry_pred\").plot(ax=ax, color=\"red\", markersize=5)\n",
    "\n",
    "plt.savefig(\"val_map.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show stored CSV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../datasets/oor/evaluation\"\n",
    "model_name = \"yolov8m_1280_v2.1\"\n",
    "\n",
    "per_image_classes = (\"container\", \"mobile_toilet\", \"scaffolding\")\n",
    "coco_classes = (\"person\", \"license_plate\", \"container\")\n",
    "\n",
    "tba_file = os.path.join(results_dir, model_name, f\"{model_name}-tba-eval.csv\")\n",
    "per_image_file = os.path.join(results_dir, model_name, f\"{model_name}-per-image-eval.csv\")\n",
    "coco_file = os.path.join(results_dir, model_name, f\"{model_name}-custom-coco-eval.csv\")\n",
    "\n",
    "tba_results = pd.read_csv(tba_file, index_col=0)\n",
    "per_image_results = pd.read_csv(per_image_file, index_col=0)\n",
    "coco_results = pd.read_csv(coco_file, index_col=0)\n",
    "\n",
    "per_image_results = per_image_results[per_image_results[\"Object Class\"].isin(per_image_classes)]\n",
    "coco_results = coco_results[coco_results[\"Object Class\"].isin(coco_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tba_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_image_results[(per_image_results[\"Size\"]==\"all\")].sort_values(by=\"Object Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_image_results[(per_image_results[\"Object Class\"]==\"container\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_results.sort_values(by=\"Object Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
