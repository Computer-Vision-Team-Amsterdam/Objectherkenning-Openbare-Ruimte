{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.source.oor_evaluation import (\n",
    "    OOREvaluator, tba_result_to_df, per_image_result_to_df, custom_coco_result_to_df\n",
    ")\n",
    "from objectherkenning_openbare_ruimte.performance_evaluation_pipeline.metrics.metrics_utils import (\n",
    "    ObjectClass\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the images (width, height)\n",
    "img_shape = (1280, 720)\n",
    "gt_base_dir = \"../datasets/oor/processed-dataset-oor-v2-2/\"\n",
    "pred_base_dir = \"../datasets/oor/inference/v2-2/\"\n",
    "output_base_dir = \"results/v2-2\"\n",
    "\n",
    "target_classes = [ObjectClass.container]\n",
    "sensitive_classes = [ObjectClass.person, ObjectClass.license_plate]\n",
    "target_conf = 0.5\n",
    "sensitive_conf = 0.3\n",
    "\n",
    "# Assume each subfolder has predictions of a different model for the same data\n",
    "models = os.listdir(pred_base_dir)\n",
    "print(models)\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = models[1]  # Pick one of the models to evaluate\n",
    "\n",
    "pred_model_dir = os.path.join(pred_base_dir, model_name)\n",
    "output_dir = os.path.join(output_base_dir, model_name)\n",
    "\n",
    "OOREval = OOREvaluator(\n",
    "    ground_truth_base_folder=gt_base_dir,\n",
    "    predictions_base_folder=pred_model_dir,\n",
    "    output_folder=output_dir,\n",
    "    predictions_image_shape=img_shape,\n",
    "    model_name=model_name,\n",
    "    pred_annotations_rel_path=\"detected_labels\",\n",
    "    splits=splits,\n",
    "    target_classes=target_classes,\n",
    "    sensitive_classes=sensitive_classes,\n",
    "    target_classes_conf=target_conf,\n",
    "    sensitive_classes_conf=sensitive_conf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Blurred Area evaluation\n",
    "tba_results = OOREval.evaluate_tba()\n",
    "tba_df = tba_result_to_df(tba_results)\n",
    "tba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per Image evaluation\n",
    "per_image_results = OOREval.evaluate_per_image()\n",
    "per_image_df = per_image_result_to_df(per_image_results)\n",
    "per_image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom COCO evaluation\n",
    "coco_results = OOREval.evaluate_coco(confidence_threshold=0.1)\n",
    "coco_df = custom_coco_result_to_df(coco_results)\n",
    "coco_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"v2-2\"  # Dataset name used in plot title\n",
    "\n",
    "model_name = models[1]  # Pick one of the models to evaluate\n",
    "splits = [\"val\", \"test\"]  # Only compute curves for these splits\n",
    "\n",
    "show_plot = True  # If False, plot will only be saved, not shown\n",
    "\n",
    "pred_model_dir = os.path.join(pred_base_dir, model_name)\n",
    "output_dir = os.path.join(output_base_dir, model_name)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "OOREval = OOREvaluator(\n",
    "    ground_truth_base_folder=gt_base_dir,\n",
    "    predictions_base_folder=pred_model_dir,\n",
    "    output_folder=output_dir,\n",
    "    predictions_image_shape=img_shape,\n",
    "    dataset_name=dataset,\n",
    "    model_name=model_name,\n",
    "    pred_annotations_rel_path=\"detected_labels\",\n",
    "    splits=splits,\n",
    "    target_classes=target_classes,\n",
    "    sensitive_classes=sensitive_classes,\n",
    "    target_classes_conf=target_conf,\n",
    "    sensitive_classes_conf=sensitive_conf,\n",
    "    single_size_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOREval.plot_tba_pr_f_curves(show_plot=show_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOREval.plot_per_image_pr_f_curves(show_plot=show_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed look into one specific model / run\n",
    "\n",
    "**NOTE:** this is dev code, do not expect it to work as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = splits[1]\n",
    "model = models[2]\n",
    "\n",
    "gt_annotations_folder = f\"{gt_base_dir}/labels/{split}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frame metadata\n",
    "\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "from typing import List, Union\n",
    "\n",
    "from cvtoolkit.datasets.yolo_labels_dataset import YoloLabelsDataset\n",
    "\n",
    "metadata_folder = \"../../datasets/oor/metadata\"\n",
    "\n",
    "RD_CRS = \"EPSG:28992\"  # CRS code for the Dutch Rijksdriehoek coordinate system\n",
    "LAT_LON_CRS = \"EPSG:4326\"  # CRS code for WGS84 latitude/longitude coordinate system\n",
    "\n",
    "def metadata_to_video_name(metadata_name: str) -> str:\n",
    "    metadata_split = metadata_name.split(sep=\"-\", maxsplit=1)\n",
    "    return f\"{metadata_split[0]}-0-{metadata_split[1]}\"\n",
    "\n",
    "def load_metadata_csv(metadata_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(metadata_file)\n",
    "    video_name = metadata_to_video_name(pathlib.Path(metadata_file).stem)\n",
    "    df[\"frame_name\"] = [f\"{video_name}_{frame_id:04}\" for frame_id in df[\"new_frame_id\"]]\n",
    "    return df.set_index(\"frame_name\")\n",
    "\n",
    "def get_target_cls_file_names(yolo_annotations_folder: str, target_cls: Union[ObjectClass, None] = None) -> List[str]:\n",
    "    yolo_dataset = YoloLabelsDataset(\n",
    "        folder_path=yolo_annotations_folder,\n",
    "        image_area=img_shape[0]*img_shape[1],\n",
    "    )\n",
    "    if target_cls:\n",
    "        yolo_dataset.filter_by_class(target_cls.value)\n",
    "    target_labels = yolo_dataset._filtered_labels\n",
    "    return [k for k, v in target_labels.items() if len(v) > 0]\n",
    "\n",
    "metadata_files = pathlib.Path(metadata_folder).glob(\"*.csv\")\n",
    "metadata_df = pd.concat(\n",
    "    [load_metadata_csv(metadata_file) for metadata_file in metadata_files]\n",
    ")\n",
    "\n",
    "metadata_gdf = gpd.GeoDataFrame(\n",
    "    metadata_df,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        x=metadata_df.gps_lon,\n",
    "        y=metadata_df.gps_lat,\n",
    "        crs=LAT_LON_CRS,\n",
    "    ),\n",
    ").to_crs(RD_CRS)\n",
    "\n",
    "del metadata_df, metadata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all detections of containers\n",
    "\n",
    "# Ground truth\n",
    "gt_container_names = get_target_cls_file_names(gt_annotations_folder, ObjectClass.container)\n",
    "keep_index = [frame in gt_container_names for frame in metadata_gdf.index]\n",
    "gt_gdf = metadata_gdf[keep_index]\n",
    "gt_gdf = gt_gdf[[\"gps_state\", \"geometry\"]]\n",
    "\n",
    "# Predictions\n",
    "pred_folder = f\"{pred_base_dir}/{model}/labels/{split}\"\n",
    "\n",
    "pred_container_names = get_target_cls_file_names(pred_folder, ObjectClass.container)\n",
    "keep_index = [frame in pred_container_names for frame in metadata_gdf.index]\n",
    "pred_gdf = metadata_gdf[keep_index]\n",
    "pred_gdf = pred_gdf[[\"gps_state\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances between ground truth and detections\n",
    "gt_gdf[\"distance\"] = gt_gdf[\"geometry\"].distance(pred_gdf[\"geometry\"].unary_union)\n",
    "pred_gdf[\"distance\"] = pred_gdf[\"geometry\"].distance(gt_gdf[\"geometry\"].unary_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance statistics\n",
    "import numpy as np\n",
    "\n",
    "stats = {\n",
    "    \"distance\": np.arange(0, 26, 5),\n",
    "    \"fnr\": [],\n",
    "    \"fpr\": [],\n",
    "}\n",
    "\n",
    "gt_total = len(gt_gdf)\n",
    "pred_total = len(pred_gdf)\n",
    "\n",
    "for dst in stats[\"distance\"]:\n",
    "    fn = np.count_nonzero(gt_gdf[\"distance\"] > dst)\n",
    "    fp = np.count_nonzero(pred_gdf[\"distance\"] > dst)\n",
    "    stats[\"fnr\"].append(fn/gt_total)\n",
    "    stats[\"fpr\"].append(fp/pred_total)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results on a map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "joined_gdf = gt_gdf.join(pred_gdf, how=\"outer\", lsuffix=\"_gt\", rsuffix=\"_pred\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "joined_gdf.set_geometry(\"geometry_gt\").plot(ax=ax, markersize=20)\n",
    "joined_gdf.set_geometry(\"geometry_pred\").plot(ax=ax, color=\"red\", markersize=5)\n",
    "\n",
    "plt.savefig(\"val_map.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show stored CSV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../datasets/oor/evaluation\"\n",
    "model_name = \"yolov8m_1280_v2.1\"\n",
    "\n",
    "per_image_classes = (\"container\", \"mobile_toilet\", \"scaffolding\")\n",
    "coco_classes = (\"person\", \"license_plate\", \"container\")\n",
    "\n",
    "tba_file = os.path.join(results_dir, model_name, f\"{model_name}-tba-eval.csv\")\n",
    "per_image_file = os.path.join(results_dir, model_name, f\"{model_name}-per-image-eval.csv\")\n",
    "coco_file = os.path.join(results_dir, model_name, f\"{model_name}-custom-coco-eval.csv\")\n",
    "\n",
    "tba_df = pd.read_csv(tba_file, index_col=0)\n",
    "per_image_df = pd.read_csv(per_image_file, index_col=0)\n",
    "coco_df = pd.read_csv(coco_file, index_col=0)\n",
    "\n",
    "per_image_df = per_image_df[per_image_df[\"Object Class\"].isin(per_image_classes)]\n",
    "coco_df = coco_df[coco_df[\"Object Class\"].isin(coco_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_image_df[(per_image_df[\"Size\"]==\"all\")].sort_values(by=\"Object Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_image_df[(per_image_df[\"Size\"]==\"all\")].sort_values(by=\"Object Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_image_df[(per_image_df[\"Object Class\"]==\"container\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_df.sort_values(by=\"Object Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
