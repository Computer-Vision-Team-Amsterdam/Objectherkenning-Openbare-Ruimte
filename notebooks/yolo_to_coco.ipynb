{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/code/siddharthkumarsah/convert-yolo-annotations-to-coco-pascal-voc?scriptVersionId=123233495&cellId=1\n",
    "\n",
    "# This Python code converts a dataset in YOLO format into the COCO format. \n",
    "# The YOLO dataset contains images of bottles and the bounding box annotations in the \n",
    "# YOLO format. The COCO format is a widely used format for object detection datasets.\n",
    "\n",
    "# The input and output directories are specified in the code. The categories for \n",
    "# the COCO dataset are also defined, with only one category for \"bottle\". A dictionary for the COCO dataset is initialized with empty values for \"info\", \"licenses\", \"images\", and \"annotations\".\n",
    "\n",
    "# The code then loops through each image in the input directory. The dimensions \n",
    "# of the image are extracted and added to the COCO dataset as an \"image\" dictionary, \n",
    "# including the file name and an ID. The bounding box annotations for each image are \n",
    "# read from a text file with the same name as the image file, and the coordinates are \n",
    "# converted to the COCO format. The annotations are added to the COCO dataset as an \n",
    "# \"annotation\" dictionary, including an ID, image ID, category ID, bounding box coordinates,\n",
    "# area, and an \"iscrowd\" flag.\n",
    "\n",
    "# The COCO dataset is saved as a JSON file in the output directory.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set the paths for the input and output directories\n",
    "data_dir = '../../datasets/oor/processed-merged-batches-first-official-training-dataset-oor'\n",
    "split = 'val'\n",
    "output_dir = data_dir\n",
    "\n",
    "image_dir = os.path.join(data_dir, 'images', split)\n",
    "label_dir = os.path.join(data_dir, 'labels', split)\n",
    "\n",
    "# Define the categories for the COCO dataset\n",
    "categories = [{\"id\": 0, \"name\": \"person\"},\n",
    "              {\"id\": 1, \"name\": \"license plate\"},\n",
    "              {\"id\": 2, \"name\": \"container\"},\n",
    "              {\"id\": 3, \"name\": \"mobile toilet\"},\n",
    "              {\"id\": 4, \"name\": \"scaffolding\"}]\n",
    "\n",
    "# Define the COCO dataset dictionary\n",
    "coco_dataset = {\n",
    "    \"info\": {},\n",
    "    \"licenses\": [],\n",
    "    \"categories\": categories,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# Loop through the images in the input directory\n",
    "for image_file in os.listdir(image_dir):\n",
    "    \n",
    "    # Load the image and get its dimensions\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Add the image to the COCO dataset\n",
    "    image_dict = {\n",
    "        \"id\": image_file.split('.')[0],\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"file_name\": image_file\n",
    "    }\n",
    "    coco_dataset[\"images\"].append(image_dict)\n",
    "    \n",
    "    # Load the bounding box annotations for the image\n",
    "    annotation_file = os.path.join(label_dir, f'{image_file.split(\".\")[0]}.txt')\n",
    "    if not os.path.isfile(annotation_file):\n",
    "        continue\n",
    "\n",
    "    with open(annotation_file) as f:\n",
    "        annotations = f.readlines()\n",
    "    \n",
    "        # Loop through the annotations and add them to the COCO dataset\n",
    "        for ann in annotations:\n",
    "            cl, x, y, w, h = map(float, ann.strip().split()[0:5])\n",
    "            x_min, y_min = int((x - w / 2) * width), int((y - h / 2) * height)\n",
    "            x_max, y_max = int((x + w / 2) * width), int((y + h / 2) * height)\n",
    "            ann_dict = {\n",
    "                \"id\": len(coco_dataset[\"annotations\"]),\n",
    "                \"image_id\": image_file.split('.')[0],\n",
    "                \"category_id\": int(cl),\n",
    "                \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                \"area\": (x_max - x_min) * (y_max - y_min),\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            coco_dataset[\"annotations\"].append(ann_dict)\n",
    "\n",
    "# Save the COCO dataset to a JSON file\n",
    "with open(os.path.join(output_dir, f'coco_gt_{split}.json'), 'w') as f:\n",
    "    json.dump(coco_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
