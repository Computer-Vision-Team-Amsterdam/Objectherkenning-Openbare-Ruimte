{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute distortion matrix based on a checkerboard video\n",
    "\n",
    "Code based on https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from notebooks.defisheye import DeFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkerboard dimensions (number of inner corners: (rows, columns) )\n",
    "checkerboard_dims = (6, 8)\n",
    "\n",
    "# path to extracted frames\n",
    "frames_path = \"../datasets/oor/checkerboard/frames\"\n",
    "# path to save detected checkerboards\n",
    "detections_path = \"../datasets/oor/checkerboard/detections\"\n",
    "# path to save undistorted images\n",
    "undistorted_path = \"../datasets/oor/checkerboard/undistorted\"\n",
    "\n",
    "# show checkerboard detections\n",
    "show_checkerboards = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Step 1: extract frames from video\n",
    "\n",
    "Extract a chosen number of random frames from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input video\n",
    "checkerboard_video_path = \"../datasets/oor/checkerboard/0-0-D26M03Y2024-H15M02S41.mp4\"\n",
    "\n",
    "# number of frames to use\n",
    "n_frames = 30\n",
    "\n",
    "os.makedirs(frames_path, exist_ok=True)\n",
    "\n",
    "cap = cv.VideoCapture(checkerboard_video_path)\n",
    "total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# select and save random frames\n",
    "frames = sorted(np.random.permutation(total_frames)[:n_frames])\n",
    "for frame in tqdm(frames):\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, frame)\n",
    "    res, img = cap.read()\n",
    "    if res:\n",
    "        out_path = os.path.join(frames_path, f\"frame_{frame}_raw.jpg\")\n",
    "        cv.imwrite(out_path, img)\n",
    "    else:\n",
    "        print(f\"Could not extract frame {frame} (out of {total_frames}), skipping.\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(f\"Extracted frames saved in {frames_path}. Please verify.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: detect checkerboard in frames\n",
    "\n",
    "First, manually inspect frames to check if the checkerboard is fully visible in the frame and not blurry. Remove frames that do not meet these criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria for checkerboard corner refinement\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    " \n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((np.prod(checkerboard_dims), 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:checkerboard_dims[0],0:checkerboard_dims[1]].T.reshape(-1,2)\n",
    " \n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "os.makedirs(detections_path, exist_ok=True)\n",
    "\n",
    "frames = [file for file in os.listdir(frames_path) if file.endswith(\".jpg\")]\n",
    " \n",
    "for frame in tqdm(frames):\n",
    "    img = cv.imread(os.path.join(frames_path, frame))\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, checkerboard_dims, None)\n",
    " \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    " \n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw the corners\n",
    "        cv.drawChessboardCorners(img, checkerboard_dims, corners2, ret)\n",
    " \n",
    "        if show_checkerboards:\n",
    "            cv.imshow('img', img)\n",
    "            cv.waitKey(500)\n",
    "        \n",
    "        frame_name, ext = os.path.splitext(frame)\n",
    "        out_path = os.path.join(detections_path, f\"{frame_name}_det{ext}\")\n",
    "        cv.imwrite(out_path, img)\n",
    "    else:\n",
    "        print(f\"No checkerboard found in {frame}, skipped.\")\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(f\"Detections saved in {detections_path}. Please verify.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually verify that all detected checkerboards are precise. If certain frames do not result in precise detections, remove those form the frames folder and run **Step 2** again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute the distortion correction parameters\n",
    "\n",
    "This step uses the output of **Step 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute calibration parameters\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Compute calibration error. Lower is better, in the order of 0.1 or less is acceptable.\n",
    "total_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    total_error += error\n",
    "\n",
    "print(f\"Mean error: {total_error/len(objpoints):.3f}\")\n",
    "\n",
    "print(\"\\nUse the following distortion correction parameters:\")\n",
    "print(f\"\\n- Camera matrix\\n{mtx}\")\n",
    "print(f\"\\n- Distortion coefficients\\n{dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: extract parameters needed for FFMPEG\n",
    "n_decimals = 3\n",
    "(w, h) = gray.shape[::-1]\n",
    "ffmpeg_params = dict()\n",
    "ffmpeg_params[\"cx\"] = np.round(mtx[0,2] / w, decimals=n_decimals)\n",
    "ffmpeg_params[\"cy\"] = np.round(mtx[1,2] / h, decimals=n_decimals)\n",
    "ffmpeg_params[\"k1\"] = np.round(dist[0,0], decimals=n_decimals)\n",
    "ffmpeg_params[\"k2\"] = np.round(dist[0,1], decimals=n_decimals)\n",
    "\n",
    "print(ffmpeg_params)\n",
    "\n",
    "print(f\"FFMPEG option: -vf lenscorrection=cx={ffmpeg_params['cx']}:cy={ffmpeg_params['cy']}:k1={ffmpeg_params['k1']}:k2={ffmpeg_params['k2']}:i=bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Undistort frames to verify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_params = {\n",
    "    \"camera_matrix\": mtx,\n",
    "    \"distortion_params\": dist,\n",
    "    \"input_image_size\": gray.shape[::-1],\n",
    "}\n",
    "\n",
    "os.makedirs(undistorted_path, exist_ok=True)\n",
    "\n",
    "frames = [file for file in os.listdir(frames_path) if file.endswith(\".jpg\")]\n",
    "\n",
    "fish = DeFish(params=distortion_params)\n",
    "\n",
    "for frame in tqdm(frames):\n",
    "    image = cv.imread(os.path.join(frames_path, frame))\n",
    "    image = fish.defisheye(image=image)\n",
    "    cv.imwrite(filename=os.path.join(undistorted_path, frame), img=image)\n",
    "\n",
    "print(f\"Undistorted images saved in {undistorted_path}. Please verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectherkenning-openbare-ruimte-xlfO-OLY-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
