{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b4f02f",
   "metadata": {},
   "source": [
    "#### Compute dbscan .csv file for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d610702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataset_name = 'test_ride_niek'\n",
    "annotations_file = f\"{dataset_name}.json\"    # This file is the raw azure coco annotations file.\n",
    "processed_detections_file = f\"dbscan_{dataset_name}_processed_detections.json\"\n",
    "dbscan_csv_file = f\"{dataset_name}_results_dbscan.csv\"\n",
    "ALLOWED_CATEGORIES = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc7d6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0]);  yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2]);  yB = min(boxA[3], boxB[3])\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    areaA = (boxA[2]-boxA[0])*(boxA[3]-boxA[1])\n",
    "    areaB = (boxB[2]-boxB[0])*(boxB[3]-boxB[1])\n",
    "    return inter / (areaA + areaB - inter) if (areaA+areaB-inter)>0 else 0\n",
    "\n",
    "def attach_by_iou(df_db, ann_df):\n",
    "    grouped = ann_df.groupby(['image_name','object_category'])\n",
    "    new_aids = []\n",
    "\n",
    "    for _, row in df_db.iterrows():\n",
    "        key = (row.image_name, row.object_category)\n",
    "        if key not in grouped.groups:\n",
    "            new_aids.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        cand = grouped.get_group(key)\n",
    "        # compute IoU for each candidate\n",
    "        ious = cand.apply(\n",
    "            lambda r: iou(\n",
    "                [row.x1, row.y1, row.x2, row.y2],\n",
    "                [r.x1,    r.y1,    r.x2,    r.y2]\n",
    "            ), axis=1\n",
    "        )\n",
    "        best = ious.idxmax()\n",
    "        new_aids.append(cand.loc[best, 'id'])   # ann_dfâ€™s annotation ID column is 'id'\n",
    "\n",
    "    df_db['annotation_id'] = new_aids\n",
    "    return df_db\n",
    "\n",
    "def load_data() -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "    \"\"\"Load and prepare annotation and detection data for evaluation.\n",
    "    \n",
    "    Loads the processed annotations and detections from JSON files, extracts the relevant\n",
    "    data, and adds GPS information to both annotations and detections.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[Dict], List[Dict], List[Dict]]: A tuple containing:\n",
    "            - annotations: List of ground truth annotations with GPS data\n",
    "            - detections: List of predicted detections with GPS data\n",
    "            - images: List of image metadata from the detections file\n",
    "    \"\"\"\n",
    "    with open(annotations_file, 'r') as f:\n",
    "        ground_truth_annotations = json.load(f)\n",
    "    with open(processed_detections_file, 'r') as f:\n",
    "        predicted_detections = json.load(f)\n",
    "    images = predicted_detections.get('images', [])\n",
    "    detections = predicted_detections['annotations']\n",
    "    annotations = ground_truth_annotations['annotations']\n",
    "    \n",
    "    # Add GPS data to both annotations and detections\n",
    "    add_gps_to_annotations(annotations, images)\n",
    "    add_gps_to_annotations(detections, images)\n",
    "    return annotations, detections, images\n",
    "\n",
    "def add_gps_to_annotations(annotations: List[Dict], images: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Augment each annotation with GPS data from its corresponding image.\n",
    "\n",
    "    Args:\n",
    "        annotations (List[Dict]): List of annotation dictionaries, each\n",
    "                                  containing an 'image_id' field.\n",
    "        images (List[Dict]): List of image entries (e.g., COCO images)\n",
    "                              each with 'id' and optional 'gps_data'.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: The same list of annotations, modified in place, where\n",
    "                    each annotation has a new 'gps_data' field set to the\n",
    "                    matching image's GPS info or None if unavailable.\n",
    "    \"\"\"\n",
    "    # Build a mapping from image_id to gps_data\n",
    "    image_id_to_gps = {img['id']: img.get('gps_data') for img in images}\n",
    "    for ann in annotations:\n",
    "        ann['gps_data'] = image_id_to_gps.get(ann['image_id'])\n",
    "    return annotations\n",
    "\n",
    "def filter_detections_to_annotated_images(annotations: List[Dict], \n",
    "                                          detections: List[Dict]) -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"Filter detections to only keep those from images that have ground truth annotations.\n",
    "    \n",
    "    Args:\n",
    "        annotations (List[Dict]): List of ground truth annotations\n",
    "        detections (List[Dict]): List of predicted detections\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[Dict], List[Dict]]: A tuple containing:\n",
    "            - annotations: The original annotations (unchanged)\n",
    "            - filtered_detections: Only detections from images that have ground truth annotations\n",
    "    \"\"\"\n",
    "    annotated_image_ids = set(ann['image_id'] for ann in annotations)\n",
    "    filtered_detections = [det for det in detections if det['image_id'] in annotated_image_ids]\n",
    "    return annotations, filtered_detections\n",
    "\n",
    "def get_base_filename(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the base filename from a path or URL, stripping query parameters.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Full file path or URL potentially containing query strings.\n",
    "\n",
    "    Returns:\n",
    "        str: The base filename without any directory path or query suffix.\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "    return base.split('?')[0]\n",
    "\n",
    "def create_filename_to_id_mapping(coco_data: Dict) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a lookup mapping base filenames to COCO image IDs.\n",
    "\n",
    "    Args:\n",
    "        coco_data (Dict): COCO dataset dictionary containing an 'images'\n",
    "                          list of image entries with 'file_name' and 'id'.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: Dictionary mapping each base filename (stripped of path\n",
    "                        and query) to its corresponding image ID.\n",
    "    \"\"\"\n",
    "    return {get_base_filename(img['file_name']): img['id'] \n",
    "            for img in coco_data.get('images', [])}\n",
    "    \n",
    "def group_annotations_by_image(annotations: Dict) -> Dict[int, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Organize a flat list of annotations into groups keyed by image ID.\n",
    "\n",
    "    Args:\n",
    "        annotations (Dict): Dictionary with an 'annotations' key containing\n",
    "                            a list of annotation dicts, each having an 'image_id'.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, List[Dict]]: Mapping from image_id to a list of annotations\n",
    "                               belonging to that image.\n",
    "    \"\"\"\n",
    "    annotations_by_image = {}\n",
    "    for ann in annotations['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] = []\n",
    "        annotations_by_image[img_id].append(ann)\n",
    "    return annotations_by_image\n",
    "    \n",
    "def align_coco_ids(detections_coco: str, annotations_coco: str, \n",
    "                    output_file: str) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Align image and annotation IDs between two COCO-format JSON files based on matching filenames.\n",
    "\n",
    "    Args:\n",
    "        detections_coco (str): Path to the COCO-format file containing detection data.\n",
    "        annotations_coco (str): Path to the COCO-format file containing ground truth annotations.\n",
    "        output_file (str): Path to the output file where the updated annotations will be saved.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict, Dict]: A tuple containing the original detections dictionary and the updated\n",
    "                           annotations dictionary with aligned IDs and merged metadata.\n",
    "    \"\"\"\n",
    "    print(\"Aligning IDs between COCO files...\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    with open(detections_coco, 'r') as f:\n",
    "        detections = json.load(f)\n",
    "    with open(annotations_coco, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    # Create mappings\n",
    "    detections_filename_to_id = create_filename_to_id_mapping(detections)\n",
    "    annotations_filename_to_id = create_filename_to_id_mapping(annotations)\n",
    "    \n",
    "    # Create ID mapping\n",
    "    id_mapping = {annotations_filename_to_id[filename]: det_id\n",
    "                    for filename, det_id in detections_filename_to_id.items()\n",
    "                    if filename in annotations_filename_to_id}\n",
    "    \n",
    "    # Create detections data mapping\n",
    "    detections_data = {img['id']: {\n",
    "        'gps_data': img['gps_data'],\n",
    "        'record_timestamp': img['record_timestamp']\n",
    "    } for img in detections['images']}\n",
    "    \n",
    "    # Update annotations\n",
    "    for img in annotations['images']:\n",
    "        base_filename = get_base_filename(img['file_name'])\n",
    "        if base_filename in detections_filename_to_id:\n",
    "            new_id = detections_filename_to_id[base_filename]\n",
    "            img['id'] = new_id\n",
    "            if new_id in detections_data:\n",
    "                img['gps_data'] = detections_data[new_id]['gps_data']\n",
    "                img['record_timestamp'] = detections_data[new_id]['record_timestamp']\n",
    "                img['file_name'] = base_filename\n",
    "    \n",
    "    # Update annotation IDs\n",
    "    annotations_by_image = group_annotations_by_image(annotations)\n",
    "    new_annotation_id = 1\n",
    "    \n",
    "    for old_image_id, new_image_id in id_mapping.items():\n",
    "        if old_image_id in annotations_by_image:\n",
    "            for ann in sorted(annotations_by_image[old_image_id], key=lambda x: x['id']):\n",
    "                ann['id'] = new_annotation_id\n",
    "                ann['image_id'] = new_image_id\n",
    "                new_annotation_id += 1\n",
    "    \n",
    "    # Sort and save\n",
    "    annotations['images'] = sorted(annotations['images'], key=lambda x: x['id'])\n",
    "    annotations['annotations'] = sorted(annotations['annotations'], key=lambda x: x['id'])\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(annotations, f, indent=2)\n",
    "    \n",
    "    print(f\"Matched {len(id_mapping)} images\")\n",
    "    print(f\"Total annotations: {len(annotations['annotations'])}\")\n",
    "\n",
    "def cluster_images_by_gps_and_select_per_class(annotations: List[Dict], \n",
    "                                               detections: List[Dict], \n",
    "                                               eps_meters: float = 20, \n",
    "                                               min_samples: int = 1) -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"Cluster images by GPS location and select one image per cluster per class.\n",
    "    \n",
    "    Clusters images by GPS location using DBSCAN. For each cluster and each class,\n",
    "    keeps only one image (the one with the most detections of that class).\n",
    "    Filters annotations and detections to only those in the selected images.\n",
    "    \n",
    "    Args:\n",
    "        annotations (List[Dict]): List of ground truth annotations (with gps_data)\n",
    "        detections (List[Dict]): List of predicted detections (with gps_data)\n",
    "        eps_meters (float): DBSCAN epsilon in meters. Default is 20.\n",
    "        min_samples (int): DBSCAN min_samples. Default is 1.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[Dict], List[Dict]]: A tuple containing:\n",
    "            - filtered_annotations: Annotations from selected images\n",
    "            - filtered_detections: Detections from selected images\n",
    "    \"\"\"\n",
    "    # Build image_id to GPS mapping from annotations\n",
    "    image_gps = {}\n",
    "    for ann in annotations:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in image_gps and ann.get('gps_data'):\n",
    "            gps = ann['gps_data']\n",
    "            if 'latitude' in gps and 'longitude' in gps:\n",
    "                image_gps[img_id] = (gps['latitude'], gps['longitude'])\n",
    "\n",
    "    image_ids = list(image_gps.keys())\n",
    "    if not image_ids:\n",
    "        return annotations, detections\n",
    "\n",
    "    coords = np.array([image_gps[img_id] for img_id in image_ids])\n",
    "    coords_rad = np.radians(coords)\n",
    "    db = DBSCAN(eps=eps_meters/6371008.8, min_samples=min_samples, metric='haversine')\n",
    "    labels = db.fit_predict(coords_rad)\n",
    "\n",
    "    # Map image_id to cluster label\n",
    "    image_id_to_cluster = {img_id: label for img_id, label in zip(image_ids, labels)}\n",
    "\n",
    "    # For each cluster and class, keep one image (with most detections of that class)\n",
    "    cluster_class_to_images = defaultdict(lambda: defaultdict(list))\n",
    "    image_class_count = defaultdict(lambda: defaultdict(int))\n",
    "    for det in detections:\n",
    "        img_id = det['image_id']\n",
    "        class_id = det['category_id']\n",
    "        if img_id in image_id_to_cluster:\n",
    "            cluster = image_id_to_cluster[img_id]\n",
    "            cluster_class_to_images[cluster][class_id].append(img_id)\n",
    "            image_class_count[img_id][class_id] += 1\n",
    "\n",
    "    selected_image_ids = set()\n",
    "    for cluster, class_to_images in cluster_class_to_images.items():\n",
    "        for class_id, img_ids in class_to_images.items():\n",
    "            best_img_id = max(img_ids, key=lambda img_id: image_class_count[img_id][class_id])\n",
    "            selected_image_ids.add(best_img_id)\n",
    "\n",
    "    filtered_annotations = [ann for ann in annotations if ann['image_id'] in selected_image_ids]\n",
    "    filtered_detections = [det for det in detections if det['image_id'] in selected_image_ids]\n",
    "    return filtered_annotations, filtered_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16c72f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#align_coco_ids(processed_detections_file, annotations_file, processed_annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75673c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 955 annotations and 737 detections from 2444 images\n",
      "Unique # of images: 373\n",
      "Unique # of images in predictions: 324\n",
      "Unique # of images: 33\n",
      "# of non-matched detections: 13\n",
      "# of matched detections: 41\n",
      "Wrote DBSCAN selection to test_ride_niek_results_dbscan.csv, retained 28 rows\n"
     ]
    }
   ],
   "source": [
    "all_annotations, all_detections, all_images = load_data()\n",
    "annotations, detections = filter_detections_to_annotated_images(all_annotations, all_detections)\n",
    "\n",
    "print(f'Loaded {len(annotations)} annotations and {len(detections)} detections from {len(all_images)} images')\n",
    "print(f'Unique # of images: {len(set(ann[\"image_id\"] for ann in annotations))}')\n",
    "print(f'Unique # of images in predictions: {len(set(det[\"image_id\"] for det in detections))}')\n",
    "# cluster & select\n",
    "filtered_anns, filtered_dets = cluster_images_by_gps_and_select_per_class(\n",
    "    annotations=annotations,\n",
    "    detections=detections,\n",
    "    eps_meters=5\n",
    ")\n",
    "\n",
    "# build a DataFrame in the same format as trackers' CSVs\n",
    "df_db = pd.DataFrame(filtered_dets)\n",
    "ann_df = pd.DataFrame(filtered_anns)\n",
    "\n",
    "id2fn = { img['id']: os.path.basename(img['file_name']) for img in all_images }\n",
    "df_db['image_name']  = df_db['image_id'].map(id2fn)\n",
    "df_db = df_db.rename(columns={'category_id':'object_category'})\n",
    "\n",
    "ann_df['image_name'] = ann_df['image_id'].map(id2fn)\n",
    "ann_df = ann_df.rename(columns={'category_id':'object_category'})\n",
    "\n",
    "df_db  = df_db [df_db['object_category'].isin(ALLOWED_CATEGORIES)]\n",
    "ann_df = ann_df[ann_df['object_category'].isin(ALLOWED_CATEGORIES)]\n",
    "\n",
    "for D in (df_db, ann_df):\n",
    "    # the `.bbox` column is a list [x,y,w,h]; stack into a 2D array\n",
    "    arr = np.vstack(D['bbox'].values)\n",
    "    D['x1'], D['y1'], D['w'], D['h'] = arr.T\n",
    "    D['x2'] = D['x1'] + D['w']\n",
    "    D['y2'] = D['y1'] + D['h']\n",
    "    \n",
    "print(f'Unique # of images: {len(df_db[\"image_name\"].unique())}')\n",
    "\n",
    "df_db = attach_by_iou(df_db, ann_df)\n",
    "\n",
    "print(f'# of non-matched detections: {df_db[\"annotation_id\"].isnull().sum()}')\n",
    "print(f'# of matched detections: {len(df_db)}')\n",
    "\n",
    "df_db = df_db[df_db['annotation_id'].notnull()]\n",
    "df_db['annotation_id'] = df_db['annotation_id'].astype(int)\n",
    "df_out = df_db[['image_name','id','object_category','annotation_id']].copy()\n",
    "df_out.columns = ['image_name','ID','object_category','annotation_id']\n",
    "df_out.to_csv(dbscan_csv_file, index=False)\n",
    "print(f\"Wrote DBSCAN selection to {dbscan_csv_file}, retained {len(df_db)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e3979",
   "metadata": {},
   "source": [
    "### Compare Tracking Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27e1796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#dataset_name = 'recording_2025-05-14'\n",
    "dataset_name = 'test_ride_niek'\n",
    "\n",
    "GT_CSV    = f'{dataset_name}_reviewed.csv'\n",
    "PRED_CSV  = f'{dataset_name}_tracks_ma30_bytetrack.csv'\n",
    "ANNOT_JSON= f'{dataset_name}.json'\n",
    "DATA_DIR  = dataset_name\n",
    "ALLOWED_CATEGORIES = [3, 4, 5]  # Categories to consider for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f2e526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(gt_csv):\n",
    "    '''\n",
    "    Load manual annotations and return a DataFrame with columns:\n",
    "    ['image_name','gt_id','object_category'].\n",
    "    Adjusts object_category from 0-4 to 1-5 to match predictions/JSON.\n",
    "    '''\n",
    "    df = pd.read_csv(gt_csv)\n",
    "    df = df.rename(columns={'ID': 'gt_id'})\n",
    "    # Shift object_category by +1 to align 0-4 â†’ 1-5\n",
    "    df['object_category'] = df['object_category'] + 1\n",
    "    return df[['image_name', 'gt_id', 'object_category']]\n",
    "\n",
    "def load_predictions(pred_csv):\n",
    "    \"\"\"\n",
    "    Load tracker outputs and return a DataFrame with columns:\n",
    "    ['image_name','trk_id','object_category','annotation_id'].\n",
    "    Strips any directory prefix by taking basename.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(pred_csv)\n",
    "    df = df.rename(columns={'ID':'trk_id'})\n",
    "    df['image_name'] = df['image_name'].apply(os.path.basename)\n",
    "    return df[['image_name','trk_id','object_category','annotation_id']]\n",
    "\n",
    "def assign_frame_indices(gt_df, pr_df):\n",
    "    '''\n",
    "    Create a global mapping from image_name to a consecutive frame index,\n",
    "    based on sorted unique image_name values across GT and predictions.\n",
    "    '''\n",
    "    unique_names = sorted(set(gt_df['image_name']).union(pr_df['image_name']))\n",
    "    name_to_frame = {name: idx+1 for idx, name in enumerate(unique_names)}\n",
    "    # Apply mapping\n",
    "    gt_df['frame'] = gt_df['image_name'].map(name_to_frame)\n",
    "    pr_df['frame'] = pr_df['image_name'].map(name_to_frame)\n",
    "    return gt_df, pr_df\n",
    "\n",
    "def load_coco_bboxes(ann_json_path, allowed_categories=None):\n",
    "    \"\"\"\n",
    "    Load COCO annotations JSON and return a DataFrame with columns:\n",
    "    ['image_name','x1','y1','x2','y2','category_id','annotation_id'].\n",
    "    Converts normalized bboxes to pixel coords using image width/height.\n",
    "    Strips any directory prefix by taking basename of file_name.\n",
    "    \"\"\"\n",
    "    coco = json.load(open(ann_json_path, 'r'))\n",
    "    img_meta = {img['id']: img for img in coco['images']}\n",
    "    records = []\n",
    "    for ann in coco['annotations']:\n",
    "        cid = ann['category_id']\n",
    "        if allowed_categories and cid not in allowed_categories:\n",
    "            continue\n",
    "        img = img_meta.get(ann['image_id'])\n",
    "        if img is None:\n",
    "            continue\n",
    "        w_img, h_img = img['width'], img['height']\n",
    "        x, y, bw, bh = ann['bbox']  # normalized [0-1]\n",
    "        px, py = int(x * w_img), int(y * h_img)\n",
    "        pw, ph = int(bw * w_img), int(bh * h_img)\n",
    "        fn = os.path.basename(img['file_name'])\n",
    "        records.append({\n",
    "            'image_name': fn,\n",
    "            'x1': px, 'y1': py,\n",
    "            'x2': px + pw, 'y2': py + ph,\n",
    "            'category_id': cid,\n",
    "            'annotation_id': ann['id']\n",
    "        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def attach_bboxes(df, ann_df, key_cols=('image_name','object_category')):\n",
    "    \"\"\"\n",
    "    For each row in df, find all matching ann_df rows on key_cols,\n",
    "    pick one at random (if any), and attach its bbox + annotation_id.\n",
    "    If no match, fill with NaN.\n",
    "    \n",
    "    df must have columns matching key_cols ('object_category' in df \n",
    "    corresponds to 'category_id' in ann_df).\n",
    "    ann_df must have ['image_name','category_id','x1','y1','x2','y2','annotation_id'].\n",
    "    \"\"\"\n",
    "    # rename for uniformity\n",
    "    ann = ann_df.rename(columns={'category_id': 'object_category'})\n",
    "    # build groups\n",
    "    groups = ann.groupby(list(key_cols))\n",
    "\n",
    "    # preallocate columns\n",
    "    out = df.copy()\n",
    "    out[['x1','y1','x2','y2','annotation_id']] = np.nan\n",
    "\n",
    "    # for reproducibility\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "\n",
    "    # for each unique key tuple, sample once and broadcast\n",
    "    for keys, subidx in out.groupby(list(key_cols)).groups.items():\n",
    "        # keys is a tuple (image_name, object_category)\n",
    "        # get candidate bboxes\n",
    "        try:\n",
    "            candidates = groups.get_group(keys)\n",
    "        except KeyError:\n",
    "            # no JSON bbox for this key\n",
    "            continue\n",
    "        # choose one row at random\n",
    "        chosen = candidates.sample(n=1, random_state=rng).iloc[0]\n",
    "        # assign to all matching df rows\n",
    "        mask = (out['image_name'] == keys[0]) & (out['object_category'] == keys[1])\n",
    "        out.loc[mask, ['x1','y1','x2','y2','annotation_id']] = \\\n",
    "            chosen[['x1','y1','x2','y2','annotation_id']].values\n",
    "\n",
    "    return out\n",
    "\n",
    "def object_level_retention(gt_df, pred_csv):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    # load predictions\n",
    "    pr = pd.read_csv(pred_csv)\n",
    "    pr['image_name'] = pr['image_name'].apply(os.path.basename)\n",
    "    print(f'Printing unique image names number in predictions: {len(pr[\"image_name\"].unique())}')\n",
    "\n",
    "    # build a unique mapping from (image_name, annotation_id) -> gt_id\n",
    "    mapping = (\n",
    "        gt_df[['image_name','annotation_id','gt_id']]\n",
    "        .dropna(subset=['annotation_id'])              # drop any NaNs\n",
    "        .astype({'annotation_id':'int'})                # ensure int dtype\n",
    "        .drop_duplicates(subset=['image_name','annotation_id'])\n",
    "    )\n",
    "\n",
    "    merged = pr.merge(\n",
    "        mapping,\n",
    "        on=['image_name','annotation_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # count how many distinct gt_id got recovered\n",
    "    recovered = set(merged['gt_id'].dropna().astype(int))\n",
    "    total_gt = gt_df['gt_id'].nunique()\n",
    "    return len(recovered), total_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a1d1270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_ride_niek - Unique GT objects: 48\n",
      "Printing unique image names number in predictions: 216\n",
      "test_ride_niek - ByteTrack:  39/48 objects recovered (81%)\n",
      "Printing unique image names number in predictions: 141\n",
      "test_ride_niek - DeepSORT:  28/48 objects recovered (58%)\n",
      "Printing unique image names number in predictions: 23\n",
      "test_ride_niek - DBSCAN  :  0/48 objects recovered (0%)\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['test_ride_niek']:\n",
    "    # Load and prepare data\n",
    "    GT_CSV = f\"{dataset}_reviewed.csv\"\n",
    "    ANNOT_JSON = f\"{dataset}.json\"\n",
    "    gt_df = load_ground_truth(GT_CSV)\n",
    "    ann_df = load_coco_bboxes(ANNOT_JSON, allowed_categories=ALLOWED_CATEGORIES)\n",
    "    gt_df = attach_bboxes(gt_df, ann_df.rename(columns={'category_id':'object_category'}), \n",
    "                            key_cols=('image_name','object_category'))\n",
    "    # Amount of unique objects in GT csv\n",
    "    unique_gt_ids = gt_df['gt_id'].nunique()\n",
    "    print(f\"{dataset} - Unique GT objects: {unique_gt_ids}\")\n",
    "    \n",
    "    for name, path in [\n",
    "        (\"ByteTrack\",  f\"{dataset}_tracks_ma30_bytetrack.csv\"),\n",
    "        (\"DeepSORT\",   f\"{dataset}_tracks_ma30_cd40_ni3_deepsort.csv\"),\n",
    "        (\"DBSCAN\",     f\"{dataset}_results_dbscan.csv\"),\n",
    "    ]:\n",
    "        kept, total = object_level_retention(gt_df, path)\n",
    "        print(f\"{dataset} - {name:8s}:  {kept}/{total} objects recovered ({kept/total:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134586cd",
   "metadata": {},
   "source": [
    "#### Debugging potential mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edb7d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation IDs in DBSCAN for 'image_name' detection_20250514_121945667.jpg:\n",
      "                          image_name   ID  object_category  annotation_id\n",
      "20  detection_20250514_121945667.jpg  498                3            728\n",
      "Annotation IDs in GT for 'image_name' detection_20250514_121945667.jpg':\n",
      "                          image_name  gt_id  object_category     x1     y1  \\\n",
      "23  detection_20250514_121945667.jpg      2                3  454.0  394.0   \n",
      "\n",
      "       x2     y2  annotation_id  \n",
      "23  482.0  431.0          431.0  \n",
      "Images in DBSCAN output: 23\n",
      "Images in GT CSV:         373\n",
      "Intersection:             10\n",
      "Intersected images: ['detection_20250514_121805969.jpg', 'detection_20250514_121810541.jpg', 'detection_20250514_121811053.jpg', 'detection_20250514_121811586.jpg', 'detection_20250514_121812135.jpg', 'detection_20250514_121945667.jpg', 'detection_20250514_121949317.jpg', 'detection_20250514_121950834.jpg', 'detection_20250514_121951354.jpg', 'detection_20250514_121952373.jpg']\n",
      "Images in DBSCAN but not in GT:\n",
      "['detection_20250514_121722127.jpg', 'detection_20250514_121734708.jpg', 'detection_20250514_121739911.jpg', 'detection_20250514_121748177.jpg', 'detection_20250514_121750230.jpg', 'detection_20250514_121757078.jpg', 'detection_20250514_121758138.jpg', 'detection_20250514_121815245.jpg', 'detection_20250514_121823137.jpg', 'detection_20250514_121907294.jpg', 'detection_20250514_122015242.jpg', 'detection_20250514_122025164.jpg', 'detection_20250514_122025693.jpg']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two lists of image names\n",
    "db = pd.read_csv(\"test_ride_niek_results_dbscan.csv\")\n",
    "db_images = set(db[\"image_name\"].unique())\n",
    "\n",
    "# Print annotation_id of an image in both db_images and gt_images\n",
    "image_filename = 'detection_20250514_121945667.jpg'\n",
    "print(f\"Annotation IDs in DBSCAN for 'image_name' {image_filename}:\")\n",
    "print(db[db['image_name'] == f'{image_filename}'])\n",
    "print(f\"Annotation IDs in GT for 'image_name' {image_filename}':\")\n",
    "print(gt_df[gt_df['image_name'] == f'{image_filename}'])\n",
    "\n",
    "print(f\"Images in DBSCAN output: {len(db_images)}\")\n",
    "gt_images = set(gt_df['image_name'].unique())\n",
    "print(f\"Images in GT CSV:         {len(gt_images)}\")\n",
    "print(f\"Intersection:             {len(db_images & gt_images)}\")\n",
    "print(f'Intersected images: {sorted(db_images & gt_images)}')\n",
    "print(\"Images in DBSCAN but not in GT:\")\n",
    "print(sorted(db_images - gt_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa100610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN IDs count: 25\n",
      "GT JSON IDs count: 955\n",
      "DBSCAN IDs not in GT JSON: []\n",
      "Intersection size: 25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load your DBSCAN output\n",
    "db = pd.read_csv(\"test_ride_niek_results_dbscan.csv\")\n",
    "db_ids = set(db['annotation_id'].astype(int))\n",
    "\n",
    "# 2) Load the ground-truth COCO JSON and pull out its annotation IDs\n",
    "with open(\"test_ride_niek.json\", 'r') as f:\n",
    "    coco = json.load(f)\n",
    "gt_ids = {ann['id'] for ann in coco['annotations']}\n",
    "\n",
    "# 3) Compare\n",
    "print(f\"DBSCAN IDs count: {len(db_ids)}\")\n",
    "print(f\"GT JSON IDs count: {len(gt_ids)}\")\n",
    "print(\"DBSCAN IDs not in GT JSON:\", sorted(db_ids - gt_ids))\n",
    "print(\"Intersection size:\", len(db_ids & gt_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b4440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
